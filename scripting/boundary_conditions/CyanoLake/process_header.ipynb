{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArthursLake_CyanoLake_BloomIndex_max_profile_Header.csv\n",
      "ArthursLake_CyanoLake_Chlorophyll-a_max_profile_Header.csv\n",
      "ArthursLake_CyanoLake_BloomIndex_min_profile_Header.csv\n",
      "ArthursLake_CyanoLake_Chlorophyll-a_min_profile_Header.csv\n",
      "ArthursLake_CyanoLake_Chlorophyll-a_mean_profile_Header.csv\n",
      "ArthursLake_CyanoLake_BloomIndex_mean_profile_Header.csv\n",
      "ArthursLake_CyanoLake_BloomIndex_std_profile_Header.csv\n",
      "ArthursLake_CyanoLake_Chlorophyll-a_med_profile_Header.csv\n",
      "ArthursLake_CyanoLake_BloomIndex_med_profile_Header.csv\n",
      "ArthursLake_CyanoLake_Chlorophyll-a_std_profile_Header.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# specify constants\n",
    "AGENCY_NAME = \"Hydro Tasmania\"\n",
    "AGENCY_CODE = \"HT\"\n",
    "PROGRAM = \"Arthurs Lake WQ\"\n",
    "PROJECT = \"ALWQ\"\n",
    "TAG = \"HT-ALWQ\"\n",
    "STATION_STATUS = \"Active\"\n",
    "LAT = \"-41.985227\"\n",
    "LONG = \"146.992343\"\n",
    "TIME_ZONE = \"GMT +6\"\n",
    "VERT_DATUM = \"mAHD\"\n",
    "NATIONAL_STATION_ID = 418\n",
    "SITE_DESCRIPTION = 418\n",
    "DEPLOYMENT = \"Floating\"\n",
    "DEPLOYMENT_POSITION = \"m from Surface\"\n",
    "VERT_REF = \"Water Surface\"\n",
    "SITE_MEAN_DEPTH = \"\"\n",
    "BAD_VALUE = 'NaN'\n",
    "EMAIL = \"\"\n",
    "SAMPLING_RATE = \"\"\n",
    "DATE = \"yyyy-mm-dd HH:MM:SS\"\n",
    "DEPTH = \"Decimal\"\n",
    "QC = \"NaN\"\n",
    "\n",
    "dir = \"../../../data-warehouse/csv/ht/alwq\"\n",
    "\n",
    "mapping_keys_df = pd.read_csv(\"mapping_keys.csv\")\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    if \"CyanoLake_\" in file and \"Data\" in file:\n",
    "            header_dict = {\n",
    "                \"Agency Name\": AGENCY_NAME,\n",
    "                \"Agency Code\": AGENCY_CODE,\n",
    "                \"Program\": PROGRAM,\n",
    "                \"Project\": PROJECT,\n",
    "                \"Tag\": TAG,\n",
    "                \"Data File Name\": file,\n",
    "                \"Location\": dir.rsplit(\"../\",1)[-1],\n",
    "                \"Station Status\": STATION_STATUS,\n",
    "                \"Lat\": LAT,\n",
    "                \"Long\": LONG,\n",
    "                \"Time Zone\": TIME_ZONE,\n",
    "                \"Vertical Datum\": VERT_DATUM,\n",
    "                \"National Station ID\": NATIONAL_STATION_ID,\n",
    "                \"Site Description\": SITE_DESCRIPTION,\n",
    "                \"Deployment\": DEPLOYMENT,\n",
    "                \"Deployment Position\": DEPLOYMENT_POSITION,\n",
    "                \"Vertical Reference\": VERT_REF,\n",
    "                \"Site Mean Depth\": SITE_MEAN_DEPTH,\n",
    "                \"Bad or Unavailable Data Value\": BAD_VALUE,\n",
    "                \"Contact Email\": EMAIL,\n",
    "                \"Variable ID\": mapping_keys_df.loc[mapping_keys_df[\"Key Value\"].str.replace(\" \",\"\") == file.split(\"_\")[2], \"Key\"].iloc[0],\n",
    "                \"Data Category\": mapping_keys_df.loc[mapping_keys_df[\"Key Value\"].str.replace(\" \",\"\") == file.split(\"_\")[2], \"Category\"].iloc[0],\n",
    "                \"Sampling Rate (min)\": SAMPLING_RATE,\n",
    "                \"Date\": DATE,\n",
    "                \"Depth\": DEPTH,\n",
    "                \"Variable\": file.split(\"_\")[2] + \" (\" + file.split(\"_\")[3] +\")\",\n",
    "                \"QC\": QC\n",
    "            }\n",
    "            \n",
    "            output_filename = file.replace(\"Data\",\"Header\")\n",
    "\n",
    "            print(output_filename)\n",
    "            file_path = os.path.join(dir, output_filename)\n",
    "\n",
    "            header_df = pd.DataFrame({\"Header\": header_dict.keys(), \"Value\": header_dict.values()})\n",
    "            # print(header_df)\n",
    "        \n",
    "            header_df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WoodsLake_CyanoLake_BloomIndex_max_profile_Header.csv\n",
      "WoodsLake_CyanoLake_Chlorophyll-a_std_profile_Header.csv\n",
      "WoodsLake_CyanoLake_BloomIndex_min_profile_Header.csv\n",
      "WoodsLake_CyanoLake_Chlorophyll-a_med_profile_Header.csv\n",
      "WoodsLake_CyanoLake_BloomIndex_mean_profile_Header.csv\n",
      "WoodsLake_CyanoLake_Chlorophyll-a_mean_profile_Header.csv\n",
      "WoodsLake_CyanoLake_Chlorophyll-a_max_profile_Header.csv\n",
      "WoodsLake_CyanoLake_BloomIndex_std_profile_Header.csv\n",
      "WoodsLake_CyanoLake_Chlorophyll-a_min_profile_Header.csv\n",
      "WoodsLake_CyanoLake_BloomIndex_med_profile_Header.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# specify constants\n",
    "AGENCY_NAME = \"Hydro Tasmania\"\n",
    "AGENCY_CODE = \"HT\"\n",
    "PROGRAM = \"Woods Lake WQ\"\n",
    "PROJECT = \"WLWQ\"\n",
    "TAG = \"HT-WLWQ\"\n",
    "STATION_STATUS = \"Active\"\n",
    "LAT = \"-42.080562\"\n",
    "LONG = \"147.004210\"\n",
    "TIME_ZONE = \"GMT +6\"\n",
    "VERT_DATUM = \"mAHD\"\n",
    "NATIONAL_STATION_ID = 462\n",
    "SITE_DESCRIPTION = 462\n",
    "DEPLOYMENT = \"Profile\"\n",
    "DEPLOYMENT_POSITION = \"m from Surface\"\n",
    "VERT_REF = \"Water Surface\"\n",
    "SITE_MEAN_DEPTH = \"\"\n",
    "BAD_VALUE = 'NaN'\n",
    "EMAIL = \"\"\n",
    "SAMPLING_RATE = \"\"\n",
    "DATE = \"yyyy-mm-dd HH:MM:SS\"\n",
    "DEPTH = \"Decimal\"\n",
    "QC = \"NaN\"\n",
    "\n",
    "dir = \"../../../data-warehouse/csv/ht/wlwq\"\n",
    "\n",
    "mapping_keys_df = pd.read_csv(\"mapping_keys.csv\")\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    if \"CyanoLake_\" in file and \"Data\" in file:\n",
    "        header_dict = {\n",
    "            \"Agency Name\": AGENCY_NAME,\n",
    "            \"Agency Code\": AGENCY_CODE,\n",
    "            \"Program\": PROGRAM,\n",
    "            \"Project\": PROJECT,\n",
    "            \"Tag\": TAG,\n",
    "            \"Data File Name\": file,\n",
    "            \"Location\": dir.rsplit(\"../\",1)[-1],\n",
    "            \"Station Status\": STATION_STATUS,\n",
    "            \"Lat\": LAT,\n",
    "            \"Long\": LONG,\n",
    "            \"Time Zone\": TIME_ZONE,\n",
    "            \"Vertical Datum\": VERT_DATUM,\n",
    "            \"National Station ID\": NATIONAL_STATION_ID,\n",
    "            \"Site Description\": SITE_DESCRIPTION,\n",
    "            \"Deployment\": DEPLOYMENT,\n",
    "            \"Deployment Position\": DEPLOYMENT_POSITION,\n",
    "            \"Vertical Reference\": VERT_REF,\n",
    "            \"Site Mean Depth\": SITE_MEAN_DEPTH,\n",
    "            \"Bad or Unavailable Data Value\": BAD_VALUE,\n",
    "            \"Contact Email\": EMAIL,\n",
    "            \"Variable ID\": mapping_keys_df.loc[mapping_keys_df[\"Key Value\"].str.replace(\" \",\"\") == file.split(\"_\")[2], \"Key\"].iloc[0],\n",
    "            \"Data Category\": mapping_keys_df.loc[mapping_keys_df[\"Key Value\"].str.replace(\" \",\"\") == file.split(\"_\")[2], \"Category\"].iloc[0],\n",
    "            \"Sampling Rate (min)\": SAMPLING_RATE,\n",
    "            \"Date\": DATE,\n",
    "            \"Depth\": DEPTH,\n",
    "            \"Variable\": file.split(\"_\")[2] + \" (\" + file.split(\"_\")[3] +\")\",\n",
    "            \"QC\": QC\n",
    "        }\n",
    "        \n",
    "        output_filename = file.replace(\"Data\",\"Header\")\n",
    "\n",
    "        print(output_filename)\n",
    "        file_path = os.path.join(dir, output_filename)\n",
    "\n",
    "        header_df = pd.DataFrame({\"Header\": header_dict.keys(), \"Value\": header_dict.values()})\n",
    "        # print(header_df)\n",
    "    \n",
    "        header_df.to_csv(file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
