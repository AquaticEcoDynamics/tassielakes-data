{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Date   Data\n",
      "0       2007-01-01 05:00:00 -2.181\n",
      "1       2007-01-01 06:00:00  0.116\n",
      "2       2007-01-01 07:00:00 -0.277\n",
      "3       2007-01-01 08:00:00 -0.656\n",
      "4       2007-01-01 09:00:00  1.640\n",
      "...                     ...    ...\n",
      "152402  2024-05-21 07:00:00 -1.002\n",
      "152403  2024-05-21 08:00:00 -0.273\n",
      "152404  2024-05-21 09:00:00  0.780\n",
      "152405  2024-05-21 10:00:00  0.782\n",
      "152406  2024-05-21 11:00:00  0.379\n",
      "\n",
      "[152390 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file and select only the first column\n",
    "df = pd.read_csv(\"../../data-lake/HT/Hydrology/Woods Lake Derived Inflows/Hydro Tasmania_WOODS LAKE AT DAM_Inflow Net (mÂ³.s)_exported 2024-07-24T143653.csv\", header=None, encoding='utf-8', dtype=str)\n",
    "\n",
    "df = df.iloc[42:,0:2]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.columns = [\"Date\", \"Data\"]\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert 'Data' to numeric\n",
    "df['Data'] = pd.to_numeric(df['Data'], errors='coerce')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date     object\n",
      "Data    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Date   Data\n",
      "0      2007-01-01 05:00:00 -2.181\n",
      "1      2007-01-01 06:00:00  0.116\n",
      "2      2007-01-01 07:00:00 -0.277\n",
      "3      2007-01-01 08:00:00 -0.656\n",
      "4      2007-01-01 09:00:00  1.640\n",
      "...                    ...    ...\n",
      "152402 2024-05-21 07:00:00 -1.002\n",
      "152403 2024-05-21 08:00:00 -0.273\n",
      "152404 2024-05-21 09:00:00  0.780\n",
      "152405 2024-05-21 10:00:00  0.782\n",
      "152406 2024-05-21 11:00:00  0.379\n",
      "\n",
      "[152390 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Convert date to desired format\n",
    "# df['Date'] = df['Date'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Drop rows with NaT in 'Date' column\n",
    "df = df.dropna(subset=['Date'])\n",
    "\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Replace empty cells with NaN\n",
    "df.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Date     Data\n",
      "0      2007-01-01 05:00:00 -2.18100\n",
      "1      2007-01-01 05:15:00 -1.60675\n",
      "2      2007-01-01 05:30:00 -1.03250\n",
      "3      2007-01-01 05:45:00 -0.45825\n",
      "4      2007-01-01 06:00:00  0.11600\n",
      "...                    ...      ...\n",
      "609620 2024-05-21 10:00:00  0.78200\n",
      "609621 2024-05-21 10:15:00  0.68125\n",
      "609622 2024-05-21 10:30:00  0.58050\n",
      "609623 2024-05-21 10:45:00  0.47975\n",
      "609624 2024-05-21 11:00:00  0.37900\n",
      "\n",
      "[609625 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Date' and average the 'Data' values for duplicate timestamps\n",
    "df = df.groupby('Date').mean().reset_index()\n",
    "\n",
    "# Set 'Date' as index for resampling\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Resample the DataFrame to 15-minute intervals and interpolate\n",
    "df = df.resample('15T').interpolate(method='linear')\n",
    "\n",
    "# Reset the index to convert it back to a column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# df['Data'] = df['Data'].clip(lower=0)\n",
    "\n",
    "# Resample the DataFrame to hourly intervals and interpolate\n",
    "# df = df.resample('H').interpolate(method='linear')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(\"Interpolated_storageNet_Inflow.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
